{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3e16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45665637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image \n",
    "image = cv2.imread(r\"C:\\Users\\admin\\Downloads\\download.jpg\") \n",
    "image = cv2.resize(image, (720, 640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5bbdbb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"machine learning with python/opencv_face_detector_uint8.pb\" in function 'cv::dnn::ReadProtoFromBinaryFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m MODEL_MEAN_VALUES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m78.4263377603\u001b[39m, \u001b[38;5;241m87.7689143744\u001b[39m, \u001b[38;5;241m114.895847746\u001b[39m) \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Using models \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Face \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m face \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(face2, face1) \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# age \u001b[39;00m\n\u001b[0;32m     16\u001b[0m age \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(age2, age1) \n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"machine learning with python/opencv_face_detector_uint8.pb\" in function 'cv::dnn::ReadProtoFromBinaryFile'\n"
     ]
    }
   ],
   "source": [
    "# Importing Models and set mean values \n",
    "face1 = r\"machine learning with python/opencv_face_detector.pbtxt\"\n",
    "face2 = r\"machine learning with python/opencv_face_detector_uint8.pb\"\n",
    "age1 = r\"machine learning with python/age_deploy.prototxt\"\n",
    "age2 = r\"machine learning with python/age_net.caffemodel\"\n",
    "gen1 = r\"machine learning with python/gender_deploy.prototxt\"\n",
    "gen2 = r\"machine learning with python/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746) \n",
    "\n",
    "# Using models \n",
    "# Face \n",
    "face = cv2.dnn.readNet(face2, face1) \n",
    "\n",
    "# age \n",
    "age = cv2.dnn.readNet(age2, age1) \n",
    "\n",
    "# gender \n",
    "gen = cv2.dnn.readNet(gen2, gen1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories of distribution \n",
    "la = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', \n",
    "\t'(25-32)', '(38-43)', '(48-53)', '(60-100)'] \n",
    "lg = ['Male', 'Female'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72461fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy image \n",
    "fr_cv = image.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a26798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m fr_w \u001b[38;5;241m=\u001b[39m fr_cv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m      4\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(fr_cv, \u001b[38;5;241m1.0\u001b[39m, (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m), \n\u001b[0;32m      5\u001b[0m \t\t\t\t\t\t\t[\u001b[38;5;241m104\u001b[39m, \u001b[38;5;241m117\u001b[39m, \u001b[38;5;241m123\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[1;32m----> 7\u001b[0m face\u001b[38;5;241m.\u001b[39msetInput(blob) \n\u001b[0;32m      8\u001b[0m detections \u001b[38;5;241m=\u001b[39m face\u001b[38;5;241m.\u001b[39mforward()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "# Face detection \n",
    "fr_h = fr_cv.shape[0] \n",
    "fr_w = fr_cv.shape[1] \n",
    "blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300), \n",
    "\t\t\t\t\t\t\t[104, 117, 123], True, False) \n",
    "\n",
    "face.setInput(blob) \n",
    "detections = face.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e4460b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Face bounding box creation \u001b[39;00m\n\u001b[0;32m      2\u001b[0m faceBoxes \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(detections\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]): \n\u001b[0;32m      4\u001b[0m \t\n\u001b[0;32m      5\u001b[0m \t\u001b[38;5;66;03m#Bounding box creation if confidence > 0.7 \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \tconfidence \u001b[38;5;241m=\u001b[39m detections[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, i, \u001b[38;5;241m2\u001b[39m] \n\u001b[0;32m      7\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.7\u001b[39m: \n",
      "\u001b[1;31mNameError\u001b[0m: name 'detections' is not defined"
     ]
    }
   ],
   "source": [
    "# Face bounding box creation \n",
    "faceBoxes = [] \n",
    "for i in range(detections.shape[2]): \n",
    "\t\n",
    "\t#Bounding box creation if confidence > 0.7 \n",
    "\tconfidence = detections[0, 0, i, 2] \n",
    "\tif confidence > 0.7: \n",
    "\t\t\n",
    "\t\tx1 = int(detections[0, 0, i, 3]*fr_w) \n",
    "\t\ty1 = int(detections[0, 0, i, 4]*fr_h) \n",
    "\t\tx2 = int(detections[0, 0, i, 5]*fr_w) \n",
    "\t\ty2 = int(detections[0, 0, i, 6]*fr_h) \n",
    "\t\t\n",
    "\t\tfaceBoxes.append([x1, y1, x2, y2]) \n",
    "\t\t\n",
    "\t\tcv2.rectangle(fr_cv, (x1, y1), (x2, y2), \n",
    "\t\t\t\t\t(0, 255, 0), int(round(fr_h/150)), 8) \n",
    "\t\t\n",
    "faceBoxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81424cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "# Checking if face detected or not \n",
    "if not faceBoxes: \n",
    "\tprint(\"No face detected\") \n",
    "\n",
    "# Final results (otherwise) \n",
    "# Loop for all the faces detected \n",
    "for faceBox in faceBoxes: \n",
    "\t\n",
    "\t#Extracting face as per the faceBox \n",
    "\tface = fr_cv[max(0, faceBox[1]-15): \n",
    "\t\t\t\tmin(faceBox[3]+15, fr_cv.shape[0]-1), \n",
    "\t\t\t\tmax(0, faceBox[0]-15):min(faceBox[2]+15, \n",
    "\t\t\t\t\t\t\tfr_cv.shape[1]-1)] \n",
    "\t\n",
    "\t#Extracting the main blob part \n",
    "\tblob = cv2.dnn.blobFromImage( \n",
    "\t\tface, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False) \n",
    "\t\n",
    "\t#Prediction of gender \n",
    "\tgen.setInput(blob) \n",
    "\tgenderPreds = gen.forward() \n",
    "\tgender = lg[genderPreds[0].argmax()] \n",
    "\t\n",
    "\t#Prediction of age \n",
    "\tage.setInput(blob) \n",
    "\tagePreds = age.forward() \n",
    "\tage = la[agePreds[0].argmax()] \n",
    "\t\n",
    "\t#Putting text of age and gender \n",
    "\t#At the top of box \n",
    "\tcv2.putText(fr_cv, \n",
    "\t\t\t\tf'{gender}, {age}', \n",
    "\t\t\t\t(faceBox[0]-150, faceBox[1]+10), \n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, \n",
    "\t\t\t\t1.3, \n",
    "\t\t\t\t(217, 0, 0), \n",
    "\t\t\t\t4, \n",
    "\t\t\t\tcv2.LINE_AA) \n",
    "\n",
    "\tplt.figure(figsize=(7, 7)) \n",
    "\tplt.imshow(fr_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f1e86-fb40-4e81-9370-7ce6757d569c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
